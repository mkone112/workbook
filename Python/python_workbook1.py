имена аргументов могут изначально разделять передаваемые obj т.к. указатели на них(но только временно когда fx вызывается впервые)
но после повторного вызова связь разрывается(видимо происходит копирование?) при присваивании самим именам аргументво(локальным Var)
хоспаде такая тупая ерунда описана так сложно!
    пока в теле не происходит приваивание работают разделяемые ссылки
snake_case
мне кажется что это чем-то похоже на передачу указателя в C++(но почем мне знать?)
    def changer(a,b):
        a = 2   #связь разрывается(присваиваем самому параметру)
        #по сути влияет полько на вызывающий код(b сохраняет ту-же ссылку)
        #obj на который ссылается b - входные и выходные данные для fx
        b[0] = 'new'    #присваивание компоненту obj на который ссылается аргумент
    x = 1
    l = [1,2]
    changer(x,l)
    x,l         >>1,['new',2]
при обновлении состояния obj модель классов основывается на изменнии переданного self на месте
избегай модификации изменяемых args
#хотя иногда это может быть удобно,fx становятся менее независимы + в fx парадигме данные immutable и это может быть частью API-интерфейса обходящегося без создания копий
    передача копии
        func(a[:])
        #более универсально
        def func(a):
            a = a[:]
        #применение immutable
        #вывод исключений при попытке
        #излишне брутально, изменение на месте может пригодиться в будущем => ломает гибкость
        #лишают методов исходного obj
        func(tuple(a))
ЭМУЛЯЦИЯ ВЫХОДНЫХ ПАРАМЕТРОВ И МН-ВЕННЫХ РЕЗУЛЬТАТОВ ИЗ ДРУГИХ ЯП
#эмуляция передачи аргументов по ссылке
#присваивание возвращаемых кортежей аргументам
    def change(x,y):
        x = 'x'
        y = ['y']
        return x,y
    X = 1
    L = [1,2]
    X, L = change(X,L)
    X, L            >> ('x',['y'])
РАСПАКОВКА ARGS 2.x (ЯВНЫЙ ДУБЛЬ) (ПРОВЕРИТЬ ВЕСЬ ЭТОТ БЛОК)
#в 2.x можно автоматич распаковывать кортежи(only) в args передаваемых в fx
#мало извесный и редко используемый прием
#в lambda И ЦИКЛАХ тоже
    def f((a, (b,c))):
    f((1,[2,3])),f((1, 'ab'))   >> OK (ПРОВЕРИТЬ)
    def f([a,[b,c]]):       >> SyntaxErr (проверить)
#3.x - ОТСУТСТВУЕТ как и в lambda
#в циклах вроде пашет
    #~3.x/2.x
    def f(T): a, (b,c) = T
СПЕЦИАЛЬНЫЕ РЕЖИМЫ СОПОСТАВЛЕНИЕ ARGS
#дополнительные инструменты изменяющие способ сопоставления obj-args в вызове с именами-args в заголовке до момента присваивания для передачи слишком большого или слишком малого числа args, для реализации гибких сигнатур вызовов
#комбинация режимов сопоставления используется fx поддерживающих мн-во шаблонов вызова(например для обратной совместимости)
#некоторые инструменты такого рода предназначены для создания библиотек, а не приложений(не вижу особого противоречия)
    позиционные=неключевые
    ключевые
    #позволяют делать вызовы информативнее(самодокументированными) kargs служат метками для данных в вызове
        f(0,c=1,b=2)
    #позволяют пропускать args со стандартными val
        def f(a,b=2,c=3):
        f(1,c=5)
    стандартные
    #делает arg необязательным;передача из enclosing
    сбор переменного числа добавочных(не прошедших сопоставления) позиционных и ключевых args в один obj
    #varargs :от названия списков args переменной длинны в C
        *
        #в вызывающем коде позволяет упаковать произвольное число args в iterable производит распаковку в отдельные args при передаче их в fx
        #синтаксис распаковывающих вызовов появился в 2.0 (как и zip), симметричен со сбором args * в заголовке
    #при отсутствии несопоставленных аргументов - присваивает args пустой кортеж/словарь
        def f(a,*args,**kwargs):
            print(args,kwargs)
        f(1)        >> () {}
        f(1,2)       >> (2,) {}
        f(1,key='val')  >> () {'key':'val'}
        **
        #собирает ключевые args в словарь
        def f(**kwargs):print(kwargs)
        f(a=1,b=2)              >> {'a':1,'b':2}
    аргументы с передачей только по ключу(3.X)
    #позволяют принимать любое число позиционных args и конфигурационные параметры
    
        def func(*others,name)
        #or(3.x)
        def func(*,name=value)
        #пример
            def kwonly(a,*b,c):print(a,b,c)
            kwonly(1,2,c=3)             >> 1 (2,) 3
            kwonly(1,c=3)               >> 1 () 3
            kwonly(1,2,3)               >> TypeErr:missing 'c'
            def kw(a,*b,*,c)            >> SyntaxErr
            def kw(a,**,b)              >> SyntaxErr
            def kw(a,**b,c)             >> SyntaxErr
    #избавляют от написания дополнительной логики для поддержки настроки; иначе пришлось бы икспентировать args вручную
        f(x,y,z)
        f(x,y,notify=True)
#подразделяются на вызовы и определения
    #присвоение в вызове - ключевые
    #присвоение в определении - стандартные
#присвоение в вызове/заголовке - специальный синтаксис для указания порядка сопоставления args, а не оператор присваивания
Лутц использует pargs,kargs вместо args,kwargs
задача: как сэмулировать поведение range, когда она принимает несколько наборов args и имеет разные аннотации?
    #
ПОРЯДОК ARGS
#любые другие формы->SyntaxErr т.к. м.б. неоднозначны
    def f(pargs,...,sargs=val,...,[*args|*],...,name,...,sname=val,...,**kwargs)
    f(pargs,kargs,*args,**kwargs)
    f(/,positionOnlyArgs)
    #примеры
        def func(a,b,c,d): print(a,b,c,d)
        func(*(1,2),**{'d':4,'c':3})    >> 1,2,3,4
        func(1,*(2,3),**{'d':4})       >> 1,2,3,4
        func(1,c=3,*(2,),**{'d':4})     >> 1,2,3,4
        func(1,*(2,),c=3,**{'d':4})     >> 1,2,3,4
        
алгоритм сопоставления args перед присваиванием(грубо(без учета arg с передачей только по ключу)
    pargs
    kargs
    *args
    **kwargs
    стандартных значений неприсвоенны vars
    проверка передается ли каждому args только одно val
        if нет => exept
        else => выполняется присваивание
    
АННОТАЦИИ
#3.X имена аргументов могут снабжаться аннотациями - добавочный синтаксис
    var:annotation=standart_val
    #or
    var:annotation
#3.x fx тоже могут снабжаться аннотацией
#присоединяется к obj fx (видимо __annotations__)
    def f() -> annotation:
        <code>
дополненное присваивание изменяет mutable и заменяет immutable
    t = 1,2;id(t)   >> 65212464
    t += 3,4;id(t)   >> 65631456
    l = [1,2];id(l)  >> 65275824
    l += [3,4];id(l)  >> 65275824
* - итерационный контекст (только в вызывающем коде - в заголовке объединяет args только в кортеж)
fx
#obj на которые можно ссылаться и вызывать через любую var
ОБОБЩЕННОЕ ПРИМЕНЕНИЕ fx
#некоторые программы нуждаются в вызове произвольных fx не зная их args и даже имена - распространенная техника в рамках универсальных инструментов
    #применение if для выбора fx и args и их вызов обобщенным образом
    if sometest:
        action, args = func,(1,)
    else:
        action, args = func2, (1,2,3)
    action(*args)
    #пользователь выбирает произвольную fx в gui => может отсутствовать возможность hardcode такой вызов=> передача всех args(какой-то очень банальный пример)
    func3(*args)
    #полезно для fx которые вызывают другие fx(настройка,трассирока,тестирование,замер времени выполнения,возможно декораторы?)
        def tracer(func, *pargs, **kargs):
            print('calling:', func.__name__)
            return func(*pargs,**kargs)
        def func(a,b,c,d):
            return a + b + c + d
        #аргументы "перехватываются" tracer и передаются в func
        print(tracer(func,1,2,d=4,c=3))         >> calling: func >> 10
    #еще пример
    def f(a,*b,c=6,**d): print(a,b,c,d)
    f(1,2,3,x=4,y=5)            >> 1 (2,3) 6 {'y':5, 'x':4}
    f(1,2,3,x=4,y=5,c=7)         >> 1 (2,3) 7 {'y':5, 'x':4}
    #агрумент с передачей только по ключевому слову может находиться перед/после *args или включен в **kwargs при вызове
    def f(a,*b,c=6,**d): print(a,b,c,d)
    f(1,*(2,3),c=7,**dict(x=4,y=5))     >> 1 (2,3) 7 {'y': 5, 'x': 4}
    f(1,c=7,*(2,3),**dict(x=4,y=5))     >> 1 (2,3) 7 {'y': 5, 'x': 4}
    f(1,*(2,3),**dict(x=4,y=5,c=7))     >> 1 (2,3) 7 {'y': 5, 'x': 4}
    


apply(callable[, args[, kwargs]])
#2.x замена *args,**kwargs
#устаревшая в 2.3+
#вызов callable с позиционными аргументами извлечнными из args и ключевыми аргументами извлеченными из kwargs
    apply(func,args,kwargs) #~func(*args,**kwargs)
* в отличие от apply более универсальна т.к. не требует ручного расширения {xn}
    args = (2,)
    kwargs = dict(d=4,e=5)
    f(1,c=3,*args,**kwargs)                                     >> 1,2,3,4,5
    apply(f,(1,)+args,dict(list({'c':3}.items()) + list(kwargs.items())))    >> 1,2,3,4,5
ЭМУЛЯЦИЯ print 3.x
    #!python
    import sys
    def print3(*args, **kwargs):
        sep = kwargs.get('sep',' ')
        end = kwargs.get('end','\n')
        file = kwargs.get('file', sys.stdout)
        ouput = ''
        first = True
        for arg in args:
            ouput += ('' if first else sep) + str(arg)
            first = False
        file.write(ouput + end)
    #мой вариант как-то получше
    #но эмулятор print не нужный в 3.x, но работающий только в нем не особенно полезен
    def p(*values, sep = ' ',end = '\n',file=sys.stdout):
        values = [str(elt) for elt in values]
        file.write(sep.join(values) + end)
    #перехват лишних args
    def print3(*args,**kwargs):
        sep = kwargs.pop('sep', ' ')
        end = kwargs.pop('end', '\n')
        file = kwargs.pop('file', sys.stdout)
        if kwargs: raise TypeError('extra keywords: %s' % list(kwargs.keys()))
        output = ''
        first = True
        for arg in args:
            output += ('' if first else sep) + str(arg)
            first = False
        file.write(ouput+end)
КОНЦЕПЦИИ ПРОЕКТИРОВАНИЯ fx
#некоторые концепции относятся к структурному анализу и проектированию
разложение задачи на содержательные fx - сцепление
    КАЖД fx ВКЛЮЧ единственное унифицированное назначение - то что можно описать одним простым предложением => иначе не удастся повторно применить этот код
    #ориентир - стандартная библиотека python - не пиши более функциональные fx чем стандартные
взаимодействие obj - связность
    взаимодействие только через return/args = независимость
    ИСКЛЮЧЕНИЯ
        ООП
ПРИЗНАКИ ЧТО FX СЛИШКОМ БОЛЬШАЯ
    if fx занимает несколько страниц, и ее нельзя сразу увидеть целиком
    #учитывая лаконичность Python - признак плохо написанного кода
    
глобальные var могут создавать зависимости и проблемы синхронизации
побочные эффекты опасны только if их не ожидают
классы полагаются на модификацию автоматически переданного изменяемого obj self для изменения информации о состоянии КАЖД obj
self аналог this?
ВХОДНЫЕ ДАННЫЕ FX
    args
    global vars
    file/data streams
ВЫХОДНЫЕ ДАННЫЕ
    return
    mutable args
    global vars
    file/data streams(sokets)
    nonlocal vars
трасировка - отслеживание
РЕКУРСИВНЫЕ FX
#python поддерживает прямой/косвенный вызов fx сабой себя с целью организации цикла
#применяется при построении маршрутов;анализе языков;
#каждый вызов имеет свою копию local NS в стеке(lifo) вызовов времени выполения
#жрет цп вызовами fx, и mem плодя NS
ПРЯМАЯ РЕКУРСИЯ - fx вызывает себя
    #СУММА эл-тов коллекции вычисляется  при раскручивании рекурсивных вызовов по возврату(return?)
    #на КАЖД уровне вызывает себя для находжения суммы остатка списка
    def s0(L):
        print(L)    #трассировка уровней рекурсии
        if not L:
            return 0
        else:
            return L[0] + s0(L[1:])
    #or
    def s1(L):
        return 0 if not L else L[0] + s1(L[1:])
    #любые типы поддерживающие + (не смешанные) (т.к. в конце + first вместо + 0)
    #не пустые коллекции т.к. сломается на L[0]
    #len(L) == 1 возвращает элт if он единственный
    def s2(L):
        return L[0] if len(L) == 1 else L[0] + s2(L[1:])
    #любые типы поддерживающие + (не смешанные) (т.к. в конце + first вместо + 0) ВКЛЮЧ iterable(например файлы) т.к. не выполняет индексацию
    #не пустые коллекции (first, *rest = L)
    def s3(L):
        first, *rest = L
        return first if not rest else first + s3(rest)
КОСВЕННАЯ РЕКУРСИЯ - fx0 вызывает fx1 которая ... вызывает fx0
#на каждом уровне есть n вызовов fx вместо одного
    #сбор args - для удобства
    def s(*L):
        if not L: return 0
        return nonempty(L)
    def nonempty(L):
        return L[0] + s(*L[1:])
    s(1,2,3)                #на первом ур-не стека: nonempty((1,2,3)) и s(2,3)
рекурсия часто применяется в эзотерических яп
простые циклы не подходят для нелинейных итераций
список перегруженный слева
    [[[[[1], 2], 3], 4], 5]
список перегруженный справа
    [1, [2, [3, [4, [5]]]]]
generator
    .throw(exception[,val[,tb]]) -> raise exept in generator
    #return next yielded val or raise StopIteration
    #инициирует exept в генераторе в последнем yield
    #2.5+
    def gen():
        for i in range(10):
            X = yield (i+3)
            print('X=',X)
    G = gen()
    G.throw(TypeError)      >> TypeErr
    next(G)              >> StopIteration
    .close()
    #инициирует exept GeneratorExit, для полного прекращения итерации(а как еще?)
    G = gen()
    G.close()   >> #None
    next(G)     >> StopIteration
GeneratorExit
#exept инициируемоге generator.close()
АЛГОРИТМЫ ОСОВАННЫЕ НА СТЕКЕ
#явная альтернатива рекурсии
#используется в тех-же контекстах
РЕКУРСИЯ ИЛИ ОЧЕРЕДИ И СТЕКИ
#внутренне Python реализует рекурсию заталкивая данные в стек вызовов при КАЖДОМ рекурсивном вызове чтобы запомнить куда нужно позже возвратиться и продолжить
#обычно можно реализовать процедуры в рекурсивном стиле без рекурсивных вызовов используя собственный явный стек|очереди для отслеживания оставшихся шагов
    #рекурсия
    #этот пример, как и его производные не нуждается избегании циклов т.к. принимает структуры без циклов(в примерах)
    #на циклических структурах приведет к исчерпанию пространства в стеке вызовов
    def sumtree(L):
        tot = 0
        for x in L:
            #isinstance нарушает гибкость кода
            if not isinstance(x, list):
                tot += x
            else:
                tot += sumtree(x)
        return tot
    #принимает явный список для планирования посещения эл-тов вместо рекурсивных вызовов - след эл-т всегда в начале списка fifo
    #явная очередь с обходом в ширину - может давать больший контроль над процессом обхода
    #формально обходит список в ширину по уровням т.к. добавляет содержимое вложенных подсписков в конец списка fifo
    #алгоритм
    #на циклических структурах войдет в INF цикл
имя var tot - что значит?
        #по идее это дек т.к. мы вытаскиваем элты в начале и добавляем их содержимое в конец
        def sumtree(L):
            tot = 0
            #начать с копии верхнего уровня
            items = list(L)
            while items:
                front = items.pop(0)
                #isinstance нарушает гибкость кода
                if not isinstance(front, list):
                    tot += front
                else:
                    #по сути тоже ограничивает fx по типу
                    items.extend(front)     #добавляем все из вложенного подсписка
            return tot
    #альтернатива - явный стек с обходом в глубину
    #более точная эмуляция обхода с рекурсией
    #добавляет содержимое вложенных списков в начао
    #на циклических структурах войдет в INF цикл
        def sumtree(L):
            tot = 0
            items = list(L)
            while items:
                front = items.pop(0)
                if not isinstance(front, list):
                    tot += front
                else:
                    items[:0] = front
            return tot
    #извлекаем вложенные структуры и добавляем их содержимое на верхний уровень или прибавляем к результату, делая копию структуры все более плоской
        visit = lambda x: print(x, end=', ')
        def sumtree(L):
            tot = 0
            levels = [L]                #по идее это нужно чтобы заглядывать внутрь
            while levels:
                front = levels.pop(0)       #перенос списка из levels в front;Fetch/delete front path
                print(front)            #debug
                for x in front:
                    if not isinstance(x, list):
                        tot += x
                        #visit(x)
                    else:
                        levels.append(x)    #переносим на верхний уровень; Push/schedule nested lists
            return tot
        L = [1, [2, [3, 4], 5], 6, [7, 8]]
        sumtree(L)
        >>   1
            [2, [3, 4], 5]
            6
            [7, 8]
            2
            [3, 4]
            5
            7
            8
            3
            4
#Рекурсивные вызовы естественне списков с явным планированием которые они(рекурсивные вызовы) автоматизируют => предпочтительнее
#списки с явным планированием м.б. предпочтительнее при обходе структур специализированным образом,напр. по первому наилучшему совпадению которое требует явное дерево поиска упорядоченное в соотв с некоторым критерием(напр поисковой агент оценивающий веб-страницы по их СОДЕРЖ)
явное дерево поиска = список с явным планированием
ЦИКЛЫ, ПУТИ И ГРАНИЦЫ СТЕКА
#рекурсивные алг могут требовать избегания циклов|повторений, записывать пройденные пути для дальнейшего использования, расширять пространство стека
избегание циклов
#избегание посещения уже посещенных эл-тов
#в некоторых программах требуется избегать повторяейся обработки состояния достигнутого более одного раза, даже if это не приводит к зацикливанию
    #например программа с рекурсивными вызовами могла бы поддерживать список/мн-во посещенных состояний
        if state not in visited:
            visited.add(state)  #x.add(state) | x[state]=True | x.append(state)
            <обработка>
    #в нерекурсивных альтернативах - избегать добавления посещенных состояний
    #проверка на предмет дублей позволит избежать планирования состояния во второй раз но не предотвратит повторное посещение состояния, которое обходилось раньше и потому удалено из списка(?)
    #данная модель способна например отлавливать ранее посещенные URL
        visited.add(front)
        <обработка>
        items.extend([x for x in front if x not in visited])
    #некоторые программы могут нуждаться в записывании полных путей пройденных к каждому состоянию для получения решения => КАЖД эл-т в стеке|очереди из нерекурсивной схемы(пример sumtree) м.б. списком полного пути достаточный для записи посещенных состояний и СОДЕРЖ следующий эл-т подлежащий исследованию на ЛЮБОМ конце(?)
#деревья наследования классов/цепочки импортирования модулей могут создавать зацикленные стркуктуры
#вычислительные структуры вроде перестановок(?) могут требовать произвольно много циклов => рекурсия предпочтительна
ИНТРОСПЕКЦИЯ FX
#исследование obj fx, исследование деталей реалицации/св-в/etc
    испекция attr обобщенным образом
    func.__name__
        def f():pass
        x = f
        x.__name__  >> 'f'
    func.__code__
    #fx ВКЛЮЧ  присоед кодовые obj СОДЕРЖ подробные сведения о локальных var/args
        def f():
            a = 1
            b = 2
        f.__code__  >> <code object f at 0x032CFB60, file "<pyshell#12>", line 1>
        dir(f.__code__) >> [...,'co_argcount', 'co_cellvars', 'co_code', 'co_consts'
                        , 'co_filename', 'co_firstlineno', 'co_flags', 'co_freevars', 'co_kwonlyargcount', 'co_lnotab', 'co_name', 'co_names', 'co_nlocals', 'co_stacksize', 'co_varnames']
        f.__code__.co_varnames  >>  ('a', 'b')
в итераторы
    #т.к. вызов iter() возвращает self для итератора => в цикле итерация продолжается с последнего эл-та
        I = iter([1,2,3])
        next(I)         >> 1
        [elt for elt in I]  >> [2, 3]
        #хотя здесь почему-то работает не ожидаемым для меня образом(?)
        f = lambda *args:args
        L = [1,2,3,4,5]
        def myreduce(func, iterable):
            I = iter(iterable)      # для поддержки большинсва коллекций
            res = next(I)
            for elt in L:
                res = func(res, elt)
            return res
        myreduce(f,L)               >> (((((1, 1), 2), 3), 4), 5)
        #требуемое поведение
        f = lambda *args:args
        L = [1,2,3,4,5]
        def myreduce(func, iterable):
            L = list(iterable)
            res = L[0]
            for elt in L[1:]:
                res = func(res, elt)
            return res
        myreduce(f,L)               >> ((((1, 2), 3), 4), 5)


[open(path,'a').write(c*3+'\n') for c in 'abc']
[*map(str.rstrip, open(path))]      >> ['aaa','bbb','ccc']
#map принимает callable
class f():
    def __call__(self,a):
        return a
notFunc = f()
[*map(notFunc,'s']  >> ['s']
class c():
    def __init__(self,x):
        return None
[*map(c,'s')]       >> [<__main__.f obj at <adress>>]

#__init__ должен возвращать только None
class Test:
    def __init__(self):
        return 'a'
e = Test()  >> TypeErr: __init__() should return None

#включения могут применяться как разновидность операции проецирования столбцов
#стандартный api-интерфейс для работы с sql возвращает {{xn},{xn},..}
db = [('bob',35, 'mgr'), ('sue', 40, 'dev')]
[age for (name, age, job) in db]    >> [35, 40]
[*map((lambda row: row[1]), db)]     >> [35, 40]
#2.x only
[*map((lambda (name, age, job): age), db)]  >> SyntaxErr
#повтор 2.x only
map((lambda (name, age, job): age), db)    >> [35, 40]
#генераторы достигают временного разделения при выполнении(откладывание выполнения когда это возможно)(ленивый подход)
вызов next() возвращает val и модифицирует состояние итератора
контейнер = коллекция = по идее ~ var C
obj - контейнер if позволяет определить в нем наличие эл-та(но не обязательно извлечь)
генератор/итератор/etc
#паттерны
выражения генератора/генераторные fx производят генераторы
    генераторы могут вернуть итератор на вызов iter()
        итератор поддерживает протокол итерации производя следующее val на вызов next()
        #вспомогательный obj, ЛЮБОЙ obj СОДЕРЖ __next__/.next(2.x)
        #фабрика по производству val
            итератор можно получить из iterable и наоборот
                iterable - то что возвращает iterator на iter() и не генератор напр коллекции/файлы/...
автоматические методы
#пример: next() вызывающий .next|.__next__
генератор
#более изящный вид итератора, хранит состояние СОДЕРЖ местоположение в потоке выполнения и полную local NS (пока активен(по идее не истощен))
#альтернатива заблаговременному вычислению всех val с последующим сохранением и восстановлением состояния вручную посредством классов(итератор?), обеспечивая сохранение val var доступных в NS генераторной fx
#позволяет создавать итераторы используя лаконичный синтаксис без создания класса с __iter__/__next__
    #генератор чисел фибоначчи
        def fib():
            prev, curr = 0,1
            while True:
                yield curr          #запоминает где остановился поток выполнения!;генератор автоматически приостанавливает и возобнавляет состояние вокруг точки генерации val
                #тут м.б. пачка yield!
                prev, curr = curr, prev + curr
        #создание экземпляра генератора
        #тело fx не выполняется
        f = fib()
        #возвращает итератор, тело fx не выполняется
        I = itertools.islice(f,10)
        #тело fx выполняется
        next(I)
        #альтернатива с несколькими yield
        def fib():
            prev,curr = 0,1
            while True:
                yield curr
                prev, curr = curr, prev + curr
                yield curr
                prev, curr = curr, prev + curr
        #raise/return прерывает итератор на ряду с выходом из fx фо
        #stop iteration работает автоматически raise/return не требуются
        def fib(x):
            for i in range(x):
                yield i
            raise TypeError('stop iteration')
        I = fib(2)
        next(I),next(I)     >> 0,1
        next(I)           >> stop iteration
        for i in fib(2):
            print(i)       >> 0,1
            #3.3+ return выподит доп сообщение при StopIteration(присоединяет к obj StopIteration), но игнорируется в контекстах автоматических итераций(if последний эл-т был получен в контексте автоматической итерации)
                def gen(x):
                    for i in range(x):
                        yield i
                    return 'msg'
                G = gen(3)
                next(G),next(G),next(G)     >> StopIteration: msg
                G = gen(3)
                for i in G:
                    ....              >> None
                next(G)                 >> StopIteration #без msg
            #<3.3 наличие val в return в генераторной fx -> syntaxErr:'return' with argument inside generator
                def fib(x):
                    for i in range(x):
                        yield i
                    return ('message')
                I = fib(2)
                next(I),next(I),next(I) >> StopIteration: message
                #но можно использовать и return без значения для выхода
                def gen(x,delta):
                    lim = x+delta
                    while True:
                        x += 2
                        yield x
                        if x>lim:return
                G = gen(10,3)
                next(G),next(G),next(G)     >> 
РАСШИРЕННЫЙ ПРОТОКОЛ ГЕНЕРАТОРНЫХ fx: send|next
    val отправляются генератору посредством G.send(val)
        код генератора возобновляет выполнение и yield возвращает val переданное send
            if вызывается next(G)   => yield возвращает None т.к. next отправляет None
                отсюда и то что yield обычно возвращает None
            def gen():
                for i in range(10):
                    X = yield i
                print(X)
            G = gen()
            #должен вызываться next() для запуска генератора
            next(G) >> 0
            #продвинуться вперед отправив val выражению yield
            G.send(77)
            >> 77
            >> 1
            G.send(88)
            >> 88
            >> 2
            next(G)
            >> None
            >> 3
    send()
    #протокол send fx ,доступен 2.5+, возвращает аргументы send(...) в генераторах
    #осущ переход на следующий элт в серии результатов, но в отличие от next снабжает вызывающий код возможностью взаимодействия с генератором для влияния на его работу
    #для выдачи yield результата exp exp оборачивается в скобки или указывается без скобок
        def gen():
            for i in range(10):
                for i in range(10):
                    X = yield (i+3)
                    print('X=',X)
        #~
        def gen():
            for i in range(3):
                X = yield i + 3
                print('X',X)
        G = gen()
        #нельзя послать yield val отличное от None пока поток выполнения до него не добрался?
        G.send(0)    >> TypeErr: can't send non-None val to a just-started(только запустившимуся) generator
        #возвращаем выражение после yield, но не присваиваем его
        next(G)     >> 3
        #send так-же продвигает итератор и может использоваться вместе с next
        #if не указать выражение yield в скобках(не изолировать его) то в цель присваивания отправится только его значение(что разумно т.к. exp вычисляются слева направо, а yield останавливает выполнение)
        #продолжаем, передаем yield значение и присваиваем его X
        G.send(10)    >> X 10 >> 4
        #а продолжает он его уже со следующей строки и в X пишется только val yield
        G.send(10)    >> X 10 >> 5
        G.send(10)    >> StopIteration
        #оборачивание yield в скобки делает поведение более ожидаемым
        def gen():
            for i in range(10):
                X = (yield i) + 3
                print('X',X)
        #по всей видимости exept прерывает итерацию и возвращает StopIteration        
        G = gen()
        next(G)      >> 0
        next(G)      >> TypeErr: None + int
        G.send(3)     >> StopIteration
        G = gen()
        next(G)      >> 0
        #цели ожидаемо присваивается значение exp, а yield возвращает переданное ему val
        G.send(3)     >> X 6 >> 1
    #может применяться для создания генератора разрешающего прекращать свою работу отправкой кода завершения
        def gen():
            i = 0
            exit_code = None
            while exit_code != 0:
                exit_code = yield i
                i += 1
        G = gen()
        next(G)
        G.send(0)       >> StopIteration
часто для сокращения V кода классы iterable имплементируют(?) __iter__ и __next__, где __iter__ возвращает self - класс iterable и итератор самого себя
СОБСТВЕННЫЙ ИТЕРАТОР(генератор)
    #это скорее собственный генератор т.к. не хранит все val
    #генерирует {xn} фибоначчи
    class fib:
        def __init__(self):
            self.prev = 0
            self.curr = 1
        def __iter__(self):
            return self
        def __next__(self):
            value = self.curr
            self.curr += self.prev
            self.prev = value
            return value
    f = fib()
    [next(f) for i in range(10)]    >> [1, 1, 2, 3, 5, 8, 13, 21, 34, 55]
assert
#помимо прочего жрет вывод в интерактивном интерпритаторе
    assert 'a' in 'abc' >> None
все fx itertools возвращают итераторы
    .count(start=0,step=1)
    #возвращает INF итератор ~
        def count(firstval=0, step=1):
               x = firstval
               while 1:
                   yield x
                   x += step
    .cycle(iterable) -> cycle obj
    #создает INF итератор из iterable
        x = itertools.cycle([0,1])
        [next(x) for i in range(10)]    >> [0,1,0,1....]
    .islice(iterable, stop) -> islice obj
    .islice(iterable, start, stop[,step]) -> islice obj
    #создает конечный итератор из INF(или обрезает конечный)
        limited = itertools.islice(itertools.cycle([0,1]), 0, 4)
        [next(limited) for i in range(10)]  >> StopIteration
yield
#выдает val вместо возвращения
    yield from
    #возвращают итератор из iterable(в общем то ~ другим итерационным контекстам); делегирует работу вложенным генераторам(подгенераторам)/iterable
    #3.3+, расширенный синтаксис yield
        def f():
          yield from [1,2]
        I = f()
        next(I),next(I)   >> 1, 2
        next(I)         >> StopIteration
    #разумно использовать для этого не коллекции а вложенный генератор
    #в простых случаях ~ выдаче в цикле for
        def both(N):
            for i in range(N): yield i
            for i in (x ** 2 for x in range(N)): yield i
        #выпуск всех val
        [*both(5)]      >> [0, 1, 2, 3, 4, 0, 1, 4, 9, 16]
        #~ (лаконичнее и явнее)
        def both(N):
            yield from range(N)
            yield from (x ** 2 for x in range(N))
    #~ по сути делает поведение похожим на lambda + генераторное exp, но мощнее
    #в более развитых ролях позволяет подгенераторам получать val переданные send|throw напрямую из вызываюей NS и возвращать результат внешнему генератору
        #yield without from
        def inner_gen():
            for i in range(10):
                X = (yield i) + 3
                print('X',X)
        inner = inner_gen()
        def outer_gen():
            for i in inner:
                yield i
        outer = outer_gen()
        #инициализация врешнего генератора
        #поток во внутреннем возвращает i из range
        next(outer)
        #попытка передать не None в inner
        outer.send(100)            # >> TypeErr: None+ int
        #yield from
        def outer_gen():
            yield from inner
        outer = outer_gen()
        next(outer)
        outer.send(10)          >> X 13 >> 1
        #non-flat (bad)
            def outer_gen():
                def inner_gen():
                    for i in range(10):
                        X = (yield i) + 3
                        print('X', X)
                inner = inner_gen()
                for i in inner:
                    yield i
            #переписанный
            def outer_gen():
                def inner_gen():
                    for i in range(10):
                        X = (yield i) + 3
                        print('X', X)
                yield from inner_gen()
    #дает возможность разделить работу генератора на несколько подгенераторов ~ делегированию работы в fx подфункциям или методам в классе
генератор может появляться в ЛЮБОМ итерационном контексте
#бред
    class iterator:
        def __init__(self, iterable):
            self._iterable = iterable
        def __iter__(self):
            return self
        def __next__(self):
            yield from [1,2,3]
    I = iterator('abcd')
    print(next(I))                  >> вызов next возвращает генератор
СОБСТВЕННЫЙ ИТЕРАТОР
#эмуляция iter()
class iterator:
    def __init__(self, iterable):
        self._iterable = iterable
        self.i = -1
    def __iter__(self):
        return self
    def __next__(self):
        try:
            self.i += 1
            return self._iterable[self.i]
        except IndexError:
            raise StopIteration()
I = iterator('abcd')
print(next(I))
#эмуляция генератора, хотя конечно builtin range не генератор
#используя класс адаптированный к протоколу итерации возвращающий self для одного прохода, или плодит доп obj для поддержки мн-ва активных итераторов
#мощнее встроенных итераторов(генераторов) например наследованием, могут делать поведение более явным
#в качестве альтернативы fx методов в user-def-classes iterable можно исп yield для превращения их в фабрики генераторов
    class myRange:
        def __init__(self, start, stop=None, step=1):
            if start and not stop:  #if передается только один arg
                    self.stop, self.start,self.step = start, -1, step
                    #start = 0, stop - указанный
        def __next__(self):         # может быть реализован в другом классе
            while (self.stop):
                self.stop -= self.step
                self.start += self.step
                return self.start
            raise StopIteration()
    r = myRange(5)
    print(r)
dis
#модуль диассемблирования    
    .dis(x=None,*,file=None)
    #
        dis.dis('a = 1')
        >>
              1           0 LOAD_CONST               0 (1)
                          3 STORE_NAME               0 (a)
                          6 LOAD_CONST               1 (None)
                          9 RETURN_VALUE
GET/POST наследие времени без js когда данные вводились в формы
ГЕНЕРАТОРЫ И ПРИМЕНЕНИЕ FX
    f = lambda a,b,c: print('%s %s %s' % (a,b,c))
    f(*range(3))
    list(print(x.upper(), end='') for x in 'abc') >> ABC[None, None, None]
    print(*(x.upper() for x in 'spam'))         >> S P A M
конструкторы классов возвращают новый obj при передаче экземпляра этого класса
    L = [1,2]
    L is list(L)    >> False
разумеется в python уже реализована куча алг на C - зачастую нет никакого смысла использовать алг
при использовании print 2.X в 3.X интерпритатор предагает использовать скобки - такой заботливый
heapq
#модуль, реализует очереди с приоритетом с помощью bin-кучи
ИЗВРАТ
    a = [(0, 'hello'), (1, 'world')]
    for ['>']['>'>'>'], x in a:
        print(x)
    >> 'hello' >> 'world'
    #по сути ~
        for ['str'][False]...
        #что ~ for 's', x in a:
возможно присвоение любым (mutable?) {xn}
    ['s'][0] = 1    >> ok
    's' = 1       >> SyntaxErr
для установки некоторых пакетов в pip может требоваться доп по вроде microsoft c++ build tools 14(2015)