массив - непрерывная {xn} ячеек, напрямую отображает адреса на val, не имеет дополнительной внутренней логики
bin поиск
    #получает отсортированный список на входе, возвращает позицию найденного элта в списке|null
    #я встречал что-то подобное кажется в матане(метод отрезков?)
    # один из алг использующих стратегию разделяй и властвуй
    #на каждой итерации проверяется эл-т в середине оснавшегося диапазона, одна из половин остатка исключается;число эл-тов сокращается вдвое пока не останется 1 эл-т
    #никто не говорит что массив отсортирован по возрастанию
     #можно проверять что L[left] > L[right] и скажем разворачивать спискок(по идее это операция O(n)) или использовать логику наоборот(сложность минимальна)
        сложность
        #делим число на 2 пока не останется 1
            N/2^x = 1
            2^x >= N , x->0
            log2N < x , x-> 0
            P.S log(a)b = log(c)b/log(c)a
            #в худшем случае потребуется не более log2N проверок; выполняется за логарифмическое время
            #пример [1,2,3,4,5,6,7,8] поиск 6
                выбираем 4|5
                выбираем 6|7
                #худший случай
                    5 >> 7 >> 6
    #ИТЕРАТИВНЫЙ
        def binary_search(seq,val) -> 'position':
        left = 0
        right = len(seq)-1
        while left <= right:
            mid = (left + right)//2
            guess = seq[mid]
#guess - кандидат?
            if guess == val:
                return mid, seq[mid]
            #сдвигаем границы левее/правее центра
            if guess > val:
                right = mid - 1
            else:
                left = mid+1
        return 'not in seq'
        #пример использования
            import os
            from itertools import islice
            G = os.walk(r'c:\windows')
            I = islice(G, 100)
            res = sorted([item[0].split('\\')[-1] for item in I])
            val = 'MMCEx'
            def binary_search(seq, val):
                left = 0
                right = len(seq) - 1
                while left <= right:
                    mid = (left + right) // 2
                    guess = seq[mid]
                    if guess == val:
                        return mid
                    if guess > val:
                        right = mid - 1
                    else:
                        left = mid + 1
                return 'not in seq'
            print(binary_search(res, val))
    #РЕКУРСИВНЫЙ
        def binary_search (sorted_values, value, descending=False):
            def search_on_range (left, right):
                print(left, right)
                #вернуть последнюю позицию if прошли все и ничего не нашли(для дальнейшего использования)
                #возврат последней позиции (где должен бы быть эл-т), например для добавления
                #> т.к. в случае //2 right может стать меньше left
                if left >= right:
                    return (False, left)
                #успех
                #Рекурсивно передаем самой себе остаток и в нем проверяем первый эл-т
                if sorted_values[left] == value:
                    return (True, left)
                #эта конструкция избегает left+right которые могут не поместиться с mem
                middle = left + (right - left) // 2
                if sorted_values[middle] == value:
                    #if middle и left рядом => элтов уже не осталось - последний уровень стека
                    if middle == left + 1:
                        return (True, middle)
                    else:
                        return search_on_range(left, middle + 1)
                #descending? может поиск сразу нескольких val?
                if (sorted_values[middle] < value) == descending:   #тут по идее должен работать и elif
                    return search_on_range(left, middle)
                else:
                    return search_on_range(middle + 1, right)
            return search_on_range(0, len(sorted_values))
        L = [*range(100)]
        L = [0,1,2,7,7,5,6,6,6,6,6,7,1,1,1,1,1,1,1,1,1,1,1]
        #хрен его знает что это значит
        print(binary_search(L, 7, descending=True))
    #СЛЕГКА УПРОЩЕННЫЙ РЕКУРСИВНЫЙ BIN ПОИСК
        #все равно не особо понимаю
        def bin_search(L, val):
            def search_on_range(left, right):
                print(left,right)
                if left >= right:
                    return False, left
                if L[left] == val:
                    return True, left
                middle = left + (right - left) // 2
                if L[middle] == val:
                    if middle == left + 1:
                        return (True, middle)
                    else:
                        return search_on_range(left, middle + 1)
                
                elif L[middle] >= val:          
                    return search_on_range(left, middle)
                else:
                    return search_on_range(middle + 1, right)
            return search_on_range(0, len(L))         
    #МОЙ РЕКУРСИВНЫЙ BIN ПОИСК
        def bin_search_rec(seq,val, left = 0, right = 0):
            if not right: right = len(seq) - 1
            if left <= right:
                mid = (left + right) // 2
                guess = seq[mid]
                if guess == val:
                    return mid  #базовый случай 0
                elif guess > val:
                    return bin_search_rec(seq,val,left, mid-1)
                else:
                    return bin_search_rec(seq,val, mid+1,  right)
            return 'not in seq' #базовый случай 1
            
        print(bin_search_rec([*range(-7,11,2)],3) == [*range(-7,11,2)].index(3))
    #мой дерьмовый бинарный поиск
        def binary_search(L, val):
            pos = len(L) //2 -1
            step = pos // 2
            import math
            for i in range(int(math.log2(len(L))) + 1):
                #print(int(math.log2(len(L)) + 1))
                print(L[pos])
                if L[pos] == val:
                    return pos
                elif L[pos] > val:
                    pos = pos - step
                    step //=2
                else:
                    pos = pos + step
                    step //=2
            return pos, L[pos]
        print(binary_search([*range(1,101)], 1))
        [0,1,2,3,4,5,6,7]
        #совершенно кривой код т.к. позиция должна считаться суммой иначе нечего возвращать
        #зря я резал массив
            def binary_search(L, val, *, trace=True) -> 'position':
                if trace:
                    orig = L.copy()
                while L:
                    pos = len(L)//2
                    if trace:
                        trace_bin(orig, pos)
                    if L[pos] == val:
                        return len(L)/2
                    elif L[pos] > val:
                        L = L[:pos]
                    else:
                        L = L[:pos]
                return pos
            def trace_bin(L, pos):
                #разумеется трасировка не будет нормально работать т.к. приходящая позиция говно
                #print(L[pos])
                print(L)
                #скобка + (элт+,+' ') затем указатель
                scale = ' '*pos*3 + ' *'
                print(scale)
            L = [*range(1,9)]
            print(binary_search(L, 6, trace=True))        
простой поиск
#тупой поиск перебором всех эл-тов
#сложность O(n)
bigO определяет время exe в худшем случае
#анализ скорости алг(не программы) для описания относительной быстроты в худшем случае т.е. алг не будет работать медленнее O(fx); сравнение кол-ва операций O(<кол-во операций>)
#под log автор подразумевает log_2
#также используется для описания потребления mem и глубины стека
#СУЩ набор данных : алг выполняющийся за O(fx) выполнится быстрее чем алг выполняющийся за O(gx) при fx<gx
#чем больше данных тем больше разрыв между алг разных сложностей
#порядок роста - C отличные от 1 игнорируются
    for i in seq:
        print(i)    >> #O(n)
    for i in seq:
        time.sleep(1)
        print(i)    >> #O(n)
    #хотя константы могут играть роль на практике пример быстрая сортировка и сортировка слиянием + особенности реализации
#приближенная оценка; темпы роста кол-ва операций
#нотация
    рисунок квадратов на бумаге:O(n)
    рисунок складыванием бумаги:O(log(2)N)
#СКОРОСТИ РАБОТЫ АЛГ    <- слить в одно место чтобы избежать повторов
        O(1)    (постоянное время - не зависит от размера данных)
    Бинарный поиск:
        O(log(2)n) (логарифмическое время(log(c)N)
    Простой поиск:
        O(n)    (линейное время)
    Быстрая сортировка:
    #константа меньше чем у сортировки слиянием - на практике работает быстрее т.к. средний случай встречается чаще
        O(n*log(2)n)    в среднем=лучшем случае(эл-т в середине) - размер стека O(log(2)n)* число операций
        O(n^2)        в худшем(крайний эл-т) - размер стека O(n) * число операций
    Сортировка слиянием:
    #константа больше чем у быстрой сортировки - на практике медленнее быстрой сортировки т.к. средний случай встречается чаще
        O(n*log(2)n)
    Другие эфффективные алг. сортировки:
        O(n*log(2)n)
    Сортировка выбором:
        O(n^2)
    Другие медленные алг. сортировки:
        O(n^2)
    Задача о коммивояжере(прямой перебор?):
        O(n!)   (факториальное время)
    СОРТИРОВКИ
    #стырил с соотв картинки, лежит рядом, при переписывании конспекта - брать оттуда, т.к. цвет(содержащий дополнительную непонятную мне информацию)
                        BEST    AVERAGE     WORST     MEMORY      STABLE
        quicksort          nlogn    nlogn      n^2      logn        Depends 
        merge sort         nlogn    nlogn     nlogn      depends     yes
        in-place merge sort   --       --      nlogn      1         yes
        Heapsort           nlogn    nlogn     nlogn      1         no
        Insertion sort       n       n^2      n^2       1         yes
        Introsort           nlogn   nlogn     nlogn      logn       
        selection sort      n^2       n^2     n^2        1         depends
    ->  Timsort             n       nlogn    nlogn      n         yes
        Shell sort          n       nlog^2(n) nlog^2(n)   1          no
        Bubble sort         n        n^2     n^2       1         yes
    ->   Binary tree sort     n       nlogn    nlogn      n         yes
        cycle sort          --      n^2      n^2       1          no
        Library sort         --      nlogn    n^2       n          yes
        Patience sorting      --       --      nlogn     n          no
        Smoothsort          n       nlogn     nlogn     1          no
        Strand sort         n        n^2      n^2      n          yes
     ->  Tournament sort      --       nlogn    nlogn     --         --
        Coctail sort        n        n^2      n^2      1           yes
        Comb sort          --       --       n^2       1          no
        Gnome sort          n        n^2      n^2       1         yes
        Bogosort            n       n*n!      n*n!->inf   1         no
patience(англ?)
introsort(англ?)
depends(англ?)
стабильность сортировки?
#O(log(2)n):логарифмическое время, O(n):линейное время - разновидности bigO
СРЕДНЕЕ ВРЕМЯ ВЫПОЛНЕНИЯ
#средний случай
ХУДШИЙ СЛУЧАЙ
    ...
INTROSORT(?)
#сортировка
TIMSORT(?)
#гибридная сортировка (выбором(или вставкой?) и слиянием)
CYCLE SORT(?)
#сортировка
LIBRARY SORT(?)
#сортировка
PATIENCE SORTING(?)
#сортировка
SMOOTHSORT(?)
#сортировка
STRAND SORT(?)
#сортировка
TOURNAMENT SORT(?)
#сортировка
COCTAIL SORT(?)
#сортировка
COMB SORT(?)
#сортировка
GNOME SORT(?)
#сортировка в гноме?(врядли - причем здесь окружение)
?простая сортировка = выбором? быстрая?
?bin сортировка = выбором? слиянием?
СОРТИРОВКА ВЫБОРОМ?
#сложность O(n^2), медленный алг
    #Бхаргава
        проверяем n + (n-1) + ... 1 элтов - в среднем n/2 элтов (по идее ошибка), КАЖД операция занимает O(n) => O((n^2)/2) => O(n^2)
    #мое
        проверяем n + (n-1) + (n-2) + ...
#РЕАЛИЗАЦИЯ
    #Включения + своя min
        def minimum_elt(seq):
            m = seq[0]
            for i in seq[1:]:
                if i < m:
                    m = i
            return m
        # можно дополнить до iterable простым преобразованием например в list
        def selection_sort(seq):
            # учитывая постоянные удаления эл-тов из seq и необходимость удаления эл-тов
            # Лучше использовать связанный список, и использовать встроенную fx min
            return [seq.pop(seq.index(minimum_elt(seq))) for i in range(len(seq))]
        import random
        L = [*range(100)]
        random.shuffle(L)
        print(selection_sort(L))
    #ЦИКЛЫ
        def selection_sort(seq):
        res = []
        for i in range(len(seq)):
            min_index = seq.index(min(seq))
            res.append(seq.pop(min_index))
        return res
МАССИВЫ
#основа для других СД
#можно использовать для эмуляции связанных списков пока я не умею ими пользоваться
СВЯЗАННЫЕ СПИСКИ
#вроде не имеют дополнительной логики в отличие от хеш-таблиц, и напрямую отображаются на адреса mem
СОБСТВЕННАЯ РЕАЛИЗАЦИЯ
    class LinkedListNode:
        def __init__(self, data):
            self.data = data
            self.next = None
            
        def link(self, node):
            self.next = node
        
    class LinkedList:
        def __init__(self, iterable=None):
            prev = None
            self.head = None
            for elt in iterable:
                #создаем next
                curr = LinkedListNode(elt)
                #if эл-т первый - не привязываем
                if prev:
                    #привязываем prev к next
                    prev.link(curr)
                # ~ if not self.head:self.head = curr; if головы еще нет - первый эл-т
                self.head = self.head or curr
                prev = curr
        
        def __iter__(self):
            curr = self.head
            while curr:
                yield curr.data
                curr = curr.next
                
        def __repr__(self):
            return '<class LinkedList>'
            
        def __str__(self):
            elements = []
            for node in self:
                elements.append(node)
            msg = 'LinkedList(' + str(elements) + ')'
            return msg
    linked_list = LinkedList(range(10))
    print(linked_list)
#двусвязный список
#deque? - по идее дек может хранить счетчик эл-тов изменющийся при его модификации и хеш таблицу со значениями и адресами - по идее это должно решить проблемы поиска эл-та (или тупо использовать dict(т.к. он тоже упорядочен)
#бля! по идее deque вообще не должен иметь каких-то недостатков
#можно реализовать на классах
#используется для создания более сложных СД(напр хеш-табл)
#в книге кажется часто называется списком
#альтернатива например массивов
#не размещают данные(набор указателей?) непрерывно таким образом решая проблему выделения mem при переполнении массива
#для след ячейки выделяется любое подходящее место, при добавлении эл-та нужно изменить указатели только соседних эл-тов(но для одностороннего эл-ты придется обойти до этого эл-та)
#по идее работают медленнее т.к. придется пройтись по всем(в худшем случае) эл-там связанного списка
программа запрашивает у oc mem для сохранения, в ответ oc возвращает диапазон для сохранения, для хранения м-ва obj можно использовать СД вроде массива
связанные списки vs массивы
    #ПУСТЬ требуется сохранить список дел
        массив
        #подходит для произвольного доступа
            хранит данные "непрерывным куском" хотя по идее это просто непрерывный набор указателей
            #if потребуется добавить указателей места в блоке может не хватить, придется запрашивать новый больший блок для размещения всех данных непрерывно(при этом сложность порядка O(n) т.к. придется перемещать ВСЕ эл-ты)
                решение
                #предварительное "бронирование" ячейки нужного размера(по идее это и происходит в статических яп(и по идее динамических под капотом))
                    требует больше mem которая может и не использоваться
                    перемещения не избежать при заполнении ячейки
            #при удалении потребуется только сдвинуть эл-ты, новый блок в ЛЮБОМ случае не нужен
       связанные списки
       #подходит для последовательного доступа
       #не подходит для подсчета размера
       скорость выполнения(в худшем случае)
                        массив  связанный список
        чтение             O(1)       O(n)
        вставка/удаление      O(n)       O(1)       #при условии мнгновенного доступа эл-ту(удаляемому и соседним)
        послед чтение/удаление  O(n)       O(n)  
    #по идее можно объединить связанные списки с массивом
    #Гибридная структура
        #например массив связанных списков, в каждом списке имя начинается с одной буквы
        скорость выполнения
            поиск медленнее массива, но быстрее списка(зависит от соотношения их размеров)
            вставка /удаление ~ связанному списку
односвязный список
#            
СД - структура данных
многие алг полагаются на отсортированные данные
сортировку вполне можно проводить прямо при получении данных
ВСТАВКА В СЕРЕДИНУ СПИСКА?
кешированные данные обычно хранятся в хеше(dict) при запросе данных, их наличие проверяется в хеше, if их нет => они генерируются; else отдаются из кеша
БАЗОВЫЙ И РЕКУРСИВНЫЙ СЛУЧАИ
#разбитая задача в стратегии разделяй и властвуй?
#КАЖД fx состоит из двух частей - базового и рекурсивного случая
    РЕКУРСИВНЫЙ СЛУЧАЙ
    #fx вызывает саму себя
    #часть рекурсивной fx
    БАЗОВЫЙ СЛУЧАЙ
    #не итеративный
    #часть рекурсивной fx
    #fx не вызывает себя(например возвратив val) для предотвращения зацикливания
    разделяй и властвуй на примерах
        задача: поделить прямоугольник на наибольшие одинаковые квадратные участки
        #по сути рекурсивная реализация алгоритма евклида по нахождению НОД сторон
        #базовый случай - самый простой => стороны кратны
            найти max возможный для прямоугольника квадрат
                проделать тоже с остатком
                    ...
                        пока остаток не поделится на квадраты без остатка(одна сторона кратна другой)
                        max возможный квадрат для остатка - max возможный для всего прямоугольник(по алгоритму евклида)
        задача: просуммировать эл-ты массива рекурсивно
        # обычно при рекурсивной обработке СД базовый случай - СД с одним/нулем эл-тов
        # отратительный вариант
            def s(L):
                try:
                    return L[0] + s(L[1:])
                except:
                    return L[-1]
        # вроде получше
            def s(L):
                if len(L) > 1:
                    return L[0] + s(L[1:])  #при обрезке списка - задача сокращается
                else:
                    return L[0]         << Базовый случай
        # еще вариант
            def s(L):
                if L:
                    return L[0] + s(L[1:])
                else:
                    return 0
        
        задача: рекурсивный подсчет эл-то в списке
            def length(seq):
                if seq:
                    return 1 + length(seq[1:])
                else:
                    return 0
СТЕК И КУЧА
#одни из основных низкоуровневых концепций программирования(информатики)
#разные стратегии управления|выделения mem
указатель - var хранящие адреса начальных значений mem других var
низкоуровневые яп вроде C/C++ не имеют встроенного gc
отсутсвие gc порождает утечки и фрагментацию mem - замедляющие скорость работы c mem
КУЧА
#также СД типа дерево(обычно бинарное), удовлетворяющая свойству кучи
#~max-куча(min-куча(при переворачивании))
    if узел B - потомок A => ключ(А) >= ключ(B) => элт в корне наибольший
#наиболее эффективная реализация очереди с приоритетом
#используются некоторыми эффективными алг на графах
    алг. Дейкстры на d-кучах
    алг Прима
    сортировка пирамидой
    #одна из лучших сортировок
    #не имеет квадратичных наихудших сценариев
#реализуется массивом что исключает наличие указателей между ее элтами
#операции на кучей
    найти max/min эл-т в max/min-куче (найти корень)
    #позволяет находить min|max элты за O(n)|O(1)
    удалить корень
    обновить ключ
    добавить ключ
    слияние куч для создания новой кучи содержащей все эл-ты обоих куч
#варианты куч
    2-3 куча
    Двуродительская куча
    bin-куча
    #пирамида, сортирующее дерево
        val в ЛЮБОЙ вершине не меньше val потомков
        глубина ВСЕХ листьев(расстояние до корня) не отличается более чем на один слой
        последний слой заполняется слева направо без "дырок"(?)
    биномиальная
    очередь Бродала
    Куча с D потомками
    Фибоначчиева
    Куча с приоритетом самого левого
    Спаренная
    Ассиметричная
    Мягкая
    Тернарная
    Декартово дерево
ДВОИЧНОЕ УПОРЯДОЧЕННОЕ ДЕРЕВО
#для ЛЮБОЙ вершины x
    ВСЕ элты в левом поддереве меньше x
    ВСЕ элты в правом поддереве больше x
    ВСЕ элты различны
ОЧЕРЕДЬ С ПРИОРИТЕТОМ
#абстратный тип данных
КУЧА
#heap, термин изначально использовался для СД, использовалась в LISP для динамического выделения mem отсюда и название
#хранилище в mem, размер задается при запуске процесса, при завершении - mem под нее освобождается сборщиком мусора
#из-за динамической природы не контролируется напрямую cpu, а GC
#допускает динамическое выделение mem - склад для var
#использует указатели в качестве ссылок для взаимодействия
    достоинства
    #var в куче доступных из других потоков => можно использовать для global var   
    недостатки
    #var в разных местах - медленне стека
    ПРИНЦИП РАБОТЫ
    при запуске процесса - ос выделяем mem для кучи(инициализирует отмечая ее свободной)
     программа может получать указатели на области mem в куче вызовом malloc()
     или освободить вызовом free()
     для хранения данных о расположении занятых/свободных областей использется доп область mem
malloc()
#имеет эквиваленты
    просматривает кучу в поисках свободного места
    запрашивает mem у менеджера mem при ее недостатке
    возвращает указатель на подходящую область / NULL при неудаче
#программа м.б. уверена что область выделенная malloc не будет использована в другом процессе
free()
#имеет эквиваленты
    ищет указанную область в куче
    удаляет из списка занятых ее адрес
    добавляет ее в список свободных|помечает область как свободную
#переход по указателю на освобожденную mem - приводит к непредсказуемому результату
СТЕК
#сд
#нормальный(?) поиск в стеке невозможен?
#поддерживает только добаление/извлечение в/из конца
#область ram создающаяся для КАЖД потока
#при создании/удалении var - занимают освобождают mem стека => управление mem просто и логично для выполнения на CPU => быстро т.к. время цикла обновления байта стека мало т.е. этот байт привязан к кешу CPU => эффективен и быстр

недостатки
  малый V

  # переполение стека -> segmentation fault при попытке доступа к эл-там не поместившихся в стеке
  # размер задается при создании потока, КАЖД var может занимать V соотв типу данных => вынуждает заранее объявлять размер сложных СД(напр массивов)
    => неподходит для динамических СД
  var в стеке - всегда локальны
    => неподходит для global vars
достоинства
  быстр
  #похож на массив тем что все var в одном месте
    СТЕК ВЫЗОВОВ
    
    #стек хранящий данные о состоянии fx
        при вызове fx ей выделяется блок mem который используется для хранения NS/состояния вызова
        при вызове inner из outer,outer приостановливается(в частично завершенном состоянии), а inner выделяется другой блок "над первым" объединяя блоки в стек
            <outer в "подвешенном" состоянии>
            после выполнения inner ее блок(верхний) удаляется/извлекается из стеке и управление возвращается в outer
            ...
        управление возвращается из outer
      СТЕК ВЫЗОВОВ РЕКУРСИВНЫХ FX
      #работает аналогично
      #использование стека рекурсией при переборе вложенных СД позволяет избежать маркировки уже пройденных obj(каждый вызов fx в стеке "помнит" какие obj еще не пройдены)
      #жрет много mem => но можно использовать хвостовую рекурсию
ХВОСТОВАЯ РЕКУРСИЯ
#используется для сокращения потребления mem
greet - приветствие?
БЫСТРАЯ СОРТИРОВКА
#наверняка можно двигаться и в обратном направлении от низа
#использует рекурсию(всегда?), использует стратегию "разделяй и властвуй" - один из алг разделяй и властвуй;
#уникальна т.к. скорость зависит от выбора опорного эл-та
    при получении уже отсортированного массива и выбора base первым создаст стек размером с массив т.к. один массив всегда пуст
        [1,2,3,4]
        []1[2,3,4]
        []2[3,4]
        []3[4]
    #при выборе среднего эл-та эл-ты равномерно делятся по массивам и размер стека сокращается вдвое(по идее в худшем случае(упорядоченный массив))
#скорость
#один из самых быстрых алг сортировок
    КАЖДЫЙ раз массив делится на два(в худшем случае пустой и others, в лучшем поровну) => размер стека O(n)...O(log(2)n)
        первый ур. стека - один эл-т выбирается опорным, остальные делятся по массивам => перебор всех эл-тов => O(n)
            на КАЖД уровне число перебраных эл-тов всегда O(n) и это не зависит от опорного эл-та
            #? не уверен в док-ве сложности - проверить 
            I    [1, 2, 3, 4, 5, 6, 7, 8]    O(n)
            II   [1, 2, 3] 4 [5, 6, 7, 8]    O(n)
            III   [1] 2 [3]      6 [7,8]    O(n)    <- видно имеется в виду что O(n-2) ~ O(n) (т.к. C не учитываются)   но это бред же это прогрессия!? кол-во операций вроде должно уменьшаться?
                                []7[8]          <-   это уже явно другой уровень стека
            => сложность O(n*log(2)n)...O(n^2)
            # вызов log(2)n стеков, КАЖД exe за n
            ЛУЧШИЙ СЛУЧАЙ В ДАННОМ СЛУЧАЕ - СРЕДНИЙ => при выборе случайного среднего эл-та qsort в среднем завершится за O(nlog(2)n)
        
#доказывается по индукции
    if можно отсортировать 1, 2, 3 эл-та => от увеличения их колва ничего не меняеся(случай n всегда сводится к n-1)
#по сути разворачивание блоков
    базовый случай массив из 0/1 эл-та
    рекурсивный случай - массивы из 2х элтов могут меняться местами
    АЛГОРИТМ
        выбор опорного эл-та(подойдет любой)
            разделение -выбираем эл-ты больше и меньше опорного
                quicksort(left) + base + quicksort(right)
    #моя реализация
        def qs(seq):
            if len(seq) < 2:
                return seq
            base = seq[0]
            left,right = [],[]
            for i in seq[1:]:
                if i <= base:
                    left.append(i)
                else:
                    right.append(i)
            return qs(left) + [base] + qs(right)
        print(qs([1,4,1,42,5,6]))
    #включения приведут к двойному проходу по списку для left и right
    #опроный эл-т в середине
        def qs(seq):
            if len(seq) < 2:
                return seq
            pos = len(seq)//2
            base = seq[pos]
            left, right = [], []
            for i in seq[:pos] + seq[pos+1:]:
                if i <= base:
                    left.append(i)
                else:
                    right.append(i)
            return qs(left) + [base] + qs(right)
#элегантна
#сложность O(n*log(2)n)
ДОК-ВО ПО ИНДУКЦИИ
#состоит из базы и индукционного перехода
qsort
#fx стандартной библиотеки C реализация quicksort
СОРТИРОВКА СЛИЯНИЕМ?
#merge sort

ХЕШ-ТАБЛИЦЫ
#=отображение=хеш-карты=хеши
#гибридная СД - массив + хеш-fx - сд с дополнительной логикой
    скорость
        используют массивы для хранения => поиск за O(1)
#позволяет производить поиск за O(1)
#одна из самых полезных базовых СД
#используются DNS
#подходят для
  создание связи отображающей эл-ты одного мн-ва на другое
  поиск val
  исключение дублей
    РЕАЛИЗАЦИЯ
    #позволяет производить анализ производительности хеш-таблиц
    хеш fx выдает на val число, число сохраняется в массиве по соотв индексу(=> поэтому dict должен содержать hashable, hash-fx реализованы в самих obj)
    при запросе ключа его val поступает в хеш fx которая возвращает индекс снова
        ХЕШ FX
        #принимает {xn} байт и возвращает хеш сумму (число)
        #разумеется скорость хеш-fx зависит от размера эл-та
        #отображает данные на хеш суммы
        #работает в пределах выделенной mem возвращая индексы только в определенном диапазоне
        #простейшие хеш fx
          позиция назначается согласно номеру первого символа
          произведение эл-тов не вариант => 'ab' даст тоже что и 'ba'
          сумма всех хешей%размер хеша(таблицы)
          #сумма - плохой вариант лучше {xn} всех разрядов
SHA
#алг. создания хешей
            требования
                ПОСЛЕДОВАТЕЛЬНОСТЬ
                #всегда возвращает одинаковый хеш на одинаковые данные
                РАСПРЕДЕЛЕНИЕ
                #разные хеши для разных данных
                #должна распределять ключи по всему кешу равномерно(как можно шире)
            плохая хеш-fx создает скопления и коллизии
        коллизии
            простейшая стратегия - создание на месте коллизии связанного списка
            ДЛЯ ПРЕДОТВРАЩЕНИЯ КОЛЛИЗИЙ
                коэфф заполнения
                #~коэфф загрузки
                #кол-во эл-тов/кол-во ячеек в массиве
                #при недостатке ячеек - данные переносятся в новый массив(обычно в два раза больше)
                #приближенное правило - увеличивать хеш таблицу при кофф заполнения > 0.7
                в среднем хеш-таблицы работают за O(1) даже с учетом пересоздания
                хорошая хеш-fx
                
    исключение дублей?
    
    perf
    # в среднем объединяет достоинсва массива и связных списков
    # в худшем объединяет недостатки массива и связного списка
                в среднем   в худшем(мн-во коллизий|вставка/удаление из массива)
      поиск         O(1)      O(n)
      вставка        O(1)      O(n)
      удаление       O(1)      O(n)
        
#моя реализация хеш-таблицы
    class hashable():
        def __init__(self, data):
            self.data = data
        def __hash__(self):
            hash = ''
            for elt in self.data:
                hash += str(ord(elt)
            return int(hash)
        def __str__(self):
            return self.data
        def __repr__(self):
            return self.data
    a = hashable('cat')
    b = hashable('rat')
    arr = [None]*(hash(b)+1)
    arr[hash(b)] = b
    arr[hash(a)] = a
#реализация хеш-таблицы на классах с учетом размера
    import random
    from string import ascii_lowercase as ascii
    class hashable():
        def __init__(self, data):
            self.data = data
        def __hash__(self):
            hash = ''
            for elt in self.data:
                hash += str(ord(elt))
            return int(hash)
        def __str__(self):
            return self.data
        
        def __repr__(self):
            return self.data
            
    class my_hash():
        def __init__(self, iterable):
            #3 т.к. оптимальный коэфф заполнения 0.7/2
            self.hash_size = len(iterable) * 3
            self.arr = [None] * self.hash_size
            for elt in iterable:
                pos = hash(elt) % self.hash_size
                self.arr[pos] = elt

        def __setitem__(self, key, value):
            self.arr[hash(key)%self.hash_size] = value
            if len(self.arr)/ len(self) > 0.7:
                self.arr += [None]*self.hash_size
                self.hash_size *= 2
        def __len__(self):
            return self.hash_size
        def __str__(self):
            return str(self.arr)
        
        def __repr__(self):
            return str(self.arr)
    keys = []
    for i in range(20):
        word_length = random.randint(1,10)
        word = ''
        for i in range(word_length):
            pos = random.randint(0, len(ascii)-1)
            word += ascii[pos]
        keys.append(word)
    elements = [hashable(str) for str in keys]
    H = my_hash(elements)
    H[hashable('new')] = hashable('new')
    print(H)
#реализация кеширования
    def get_sorted(iterable):
        if 'cache' not in dir(get_sorted):
            get_sorted.cache = {}
        key = str(iterable)
        if key in get_sorted.cache:
            print('cached!')
            return get_sorted.cache[key]
        else:
            print('calculating')
            cache[key] = sorted(iterable)
            return get_sorted.cache[key]

    L = [1,2,3]
    import random
    random.shuffle(L)
    print('source', L)
    get_sorted(L)
ПОИСК В ШИРИНУ
    #поиск маршрута с min числом прыжков в графе
    #можно найти кратчайший путь разбив взвешенные ребра на соотв число отрезков
    #поиск на следующем уровне не начинается до прекращения поиска на предыдущем
        для этого используется очередь
    #проверка существования связи/маршрута между узлами
    #алг
        создать очередь всех узлов
            while queue:
                извлечь очередной узел
                    проверить явл ли он целью
                        да -> break
                        else ->
                        добавить их соседей в очередь

    #Breadth-First Search(BFS)
    breadth - англ?
        ПОИСК КРАТЧАЙШЕГО ПУТИ?
        ОЧЕРЕДИ
        #не поддерживает доступ к произвольным эл-там(иначе это уже не очередь а гибридная СД)
        #может быть легко реализована связным списком
        #поддерживает только добаление(постановка) в конец и извлечение из начала
    #что-то не нашел реализации для поиска кратчайшего маршрута
    #псевдокод моей реализации
    def bfs(graph, start, target):
        res = [start]
        for строка in res:
            if послед буква в эл-те res in graph:
                for соседи in graph:
                    добавляем в res новую удлинненую строку
                    if путь найден:
                        return путь
                del последняя буква в эл-те res из graph
        return 'нет путей'
    #моя реализация, пашет только с односимвольными именами узлов
        #так-же можно убрать прерывание при нахождении пути, и возвращать полный список путей для дальнейшей обработки
        def bfs(graph,start,target):
            res = [start]
            #перебираем res и пытаемся продолжить маршруты
            for node in res:
                #в конце res еще не перебран а graph уже пуст
                if node[-1] in graph:
                    #соседние узлы
                    for bound in graph[node[-1]]:
                        res.append(node + bound)
                        if res[-1].startswith(start) and res[-1].endswith(target):
                            return res[-1]
                    #избежание зацикливания
                    del graph[node[-1]]
            return res
    #моя реализация, находит маршрут
    def bfs(graph, start, target):
        graph = graph.copy()
        res = [[start]]
        for way in res:
            if way[-1] in graph:
                for bound in graph[way[-1]]:
                    res += [way + [bound]]
                    if res[-1][0] == start and res[-1][-1] == target:
                        return res[-1]
                del graph[way[-1]]
        return 'not in graph', res
    #ПРОТОТИП bfs использующий очередь и запоминающий маршрут
    from collections import deque
    graph0 = dict(S=['A', 'C'], A=['B', 'F'], C=['B', 'F'], B=[], F=[])
    graph1 = dict(A=['B'],B=['C','A'],C=['B'])
    def bfs(graph, start, target):
        orig = graph
        graph = graph.copy()
        search_queue = deque()
        if start in graph:
            seach_queue += graph[start]
        else:
            return 'start not in graph'
        seached = []
        way = []
        while seach_queue:
            node = seach_queue.popleft()
            if node not in searched:
                if node == target:
                    return True
                elif node in graph:
                    seach_queue += graph[node]
                    seached.append(node)
                    if node:
                        way.append(node)
                    else:
                        #удаляем ноду из графа
                        #удаляем все упоминания из маршрута
                        while node in way:
                            way.remove(node)
                        for key,val in graph.items():
                            if node in val:
                                ...
                if not node:
                        ...
    #бхаргава + я => проверка наличия маршрута, всесто списка посещенных - удаляем посещенные из графа
        def bfs(graph, start, target):
            search_queue = deque()
            if start in graph:
                search_queue += graph[start]
            else:
                return 'start not in graph'
            del graph[start]
            while search_queue:
                node = search_queue.popleft()
                if node == target:
                    return True
                elif node in graph:
                    search_queue += graph[node]
                    del graph[node]
            return 'not in graph'
    #бхаргава, проверка существования маршрута
        def bfs(graph, start, target):
            search_queue = deque()
            if start in graph:
                search_queue += graph[start]
            else:
                return 'start not in graph'
            searched = []
            while search_queue:
                node = search_queue.popleft()
                if node not in searched:
                    if node == target:
                        return True
                    elif node in graph:
                        search_queue += graph[node]
                        searched.append(node)
            return 'not in graph'
            
    #лучший вариант
        from collections import deque
        def bfs(graph, start, target):
            if start == target:
                return [start]
            searched = {start}
            search_queue = deque([(start, [])])
            while search_queue:
                current, path = search_queue.popleft()
                for neighbor in graph[current]:
                    if neighbor == target:
                        return path + [current, neighbor]
                    elif neighbor in searched:
                        continue
                    search_queue.append((neighbor, path + [current]))
                    searched.add(neighbor)
            return None
            
    #еще как вариант можно было бы плодить строки при добавлении|извлечении из очереди
    ВРЕМЯ ВЫПОЛНЕНИЯ
    if был пройден все граф => O(E), т.к. КАЖД вершина была добавлена в очередь => O(V) => общее время O(V+E)
ГРАФ
#исп для моделирования связей
#взвешенный граф - граф с весами
#невзвешенный граф - граф без весов
    узлы соединенные напрямую - соседи/соседние
    в направленном графе A->B : B - сосед A, но A не сосед B
    РЕАЛИЗАЦИЯ ГРАФА?
        словарь списков
            #ПРИМЕРЫ ГРАФОВ
                '''
                       Find short way from S to F
                       ┌──→ F
                       A→B  ↑
                       ↑ ↑  │
                       S→C──┘
                       '''
                graph0 = dict(S=['A', 'C'], A=['B', 'F'], C=['B', 'F'], B=[], F=[])
                '''
                       find short way from cab to bat
                             (mat)───┐
                               ↑     ↓
                         ┌──→(cat)→(bat)
                         │     ↑     ↑
                       (cab)→(car)→(bar)
                       '''
                graph1 = dict(cab=['car','cat'], car=['cat','bar'],bar=['bat'],cat=['bat','mat'],bat=[],mat=['bat'])
                graph2 = dict(A=['B'],B=['C','A'],C=['B'])
           graph = dict(START={'A':6,'B':2},A={'END':1},B={'A':3,'END':5},END={})
           #удобно получать веса ребер
           graph['START']['B']  >> 2        
        список смежности(групирует соседние эл-ты)
    ОТРИСОВКА ГРАФА
        #v1
        import networkx as nx
        import matplotlib.pyplot as plt
        def renderGraph(graph, start, target, path):
            G = nx.DiGraph()
            G.add_nodes_from(graph)
            temp = graph.items()
            pos = nx.spring_layout(G)
            for u, values in graph.items():
                for v in values:
                        G.add_edge(u,v)
            nx.draw_networkx_edges(G, pos, edgelist=[...], edge_color='#000000')
            nx.draw_networkx_nodes(G, pos,
                                   nodelist=list(set(graph)-set([start,target])),
                                   node_color='#A0CBE2',
                                   node_size=500,
                                   alpha=0.8)
            nx.draw_networkx_nodes(G,pos,
                                   nodelist=[start],
                                   node_color='#FFFF00')
            nx.draw_networkx_nodes(G,pos,
                                   nodelist=[target],
                                   node_color='#ff0000')
            nx.draw_networkx_labels(G, pos, font_size=16)
            #nx.draw(G, with_labels=True)
            plt.show()
        #ОТРИСОВКА ВЗВЕШЕННОГО ГРАФА
            import networkx as nx
            G = nx.DiGraph()
            G.add_edges_from([('A', 'B'),('C','D'),('G','D')], weight=1)
            #for u, values in graph.items():
            #    for v, weight in values.items():
            #        G.add_edges_from([(u,v)], weight=weight)
            #val_map = {'A': 1.0, 'D': 0.5714285714285714, 'H': 0.0}
            #values = [val_map.get(node, 0.45) for node in G.nodes()]
            edge_labels=dict([((u,v,),d['weight']) for u,v,d in G.edges(data=True)])
            #red_edges = [('C','D'),('D','A')]
            #edge_colors = ['black' if not edge in red_edges else 'red' for edge in G.edges()]
            pos=nx.planar_layout(G)
            nx.draw_networkx_edge_labels(G,pos,edge_labels=edge_labels)
            #nx.draw(G,pos, node_color = values, node_size=1500,edge_color=edge_colors,edge_cmap=plt.cm.Reds)
            nx.draw(G,pos,with_labels=True)
            #pylab.show()
        #более адекватно
            #Counter думаю не обязательно - но суть в целом ясна
            G = nx.DiGraph((x,y, {'weight': v} for (x,y), v in Counter(EDGES).items())
узел с min весом - узел до которого дешевле всего добраться из текущей позиции     
НАПРАВЛЕННЫЙ ГРАФ
#ориентированный граф
    A<->B ~ A-B => цикл
dag(directed acyclic graph)
ТОПОЛОГИЧЕСКАЯ СОРТИРОВКА
#алг. сортировки раскрывающий связи узлов
#способ построение упорядоченного списка на основе графа
АЛГ. ДЕЙКСТРЫ
    #посмотреть в хаггарти?
    #поиск кратчайшего маршрута/прыжков -> можно узнать число мin число прыжков сравняв все ребра
    #формально основан на том что до узла с min стоимостью нельзя добраться быстрее т.к. при выборе альтернативного маршрута стоимость будет превышать стоимость min на первом же шаге; в графе ищется путь с min стоимостью и пути к этому узлу с меньшими затратами НЕСУЩ => графы ВКЛЮЧ ребра с отриц весом - ломают алг => альтернатива перебор всех альтернативных путей => делает задачу NP-полной и лишает алг. смысла <- все это тупой маразм, пока ребра не перебраны алг будет работать
    #по идее можно использовать в графах с ребрами с отриц весом предвадительно увеличив все ребра на величину самого малого отриц веса, найти маршрут, а затем подсчитать вес на оригинальном графе
    #ТОЛЬКО В АЦИКЛИЧНЫХ, НАПРАВЛЕННЫХ, ВЗВЕШЕННЫХ графах - наиболее быстрый в таких случаях?
      алг:
           while остаются не обработанные узлы:
               выбрать узел ближайший к началу(выбрать ребро с min весом)
                 обновить стоимость соседей этого узла
                    if стоимость узла обновлена => обновить родителей
           вычислить итоговый путь
        РЕБРА С ОТРИЦАТ ВЕСОМ
        #выгода вместо потерь
        #позволяет указывать приоритетные направление для AI
    #моя реализация
    #вроде работает хорошо
        '''start, end = 'START', 'END'
        graph = dict(START={'A':6,'B':2},A={'END':1},B={'A':3,'END':5},END={})
        '''
        start, end = 'BOOK', 'DRUM'
        graph = {start:{'PLATE':5,'POSTER':0},'PLATE':{'POSTER':-7},'POSTER':{end:35},end:{}}
        costs = graph[start].copy()
        costs.update({end:float('inf')})
        parents = {child:'A' for child in graph['A']}
        parents.update({end:None})
        searched = []   #можно использовать и set на случай дублей для избежания разрастания(по идее)
        def find_lowest_cost_node(costs):
            costs = costs.copy()
            [costs.pop(node) for node in searched if node in searched]
            if costs:
                return min(zip(costs.values(),costs.keys()))[1]
        node = find_lowest_cost_node(costs)
        while node:
            cost = costs[node]
            neighbors = graph[node]
            for neighbor in neighbors:
                new_cost = cost + neighbors[neighbor]
                if costs[neighbor] > new_cost:
                    costs[neighbor] = new_cost
                    parents[neighbor] = node
            searched.append(node)
            node = find_lowest_cost_node(costs)
        #построение маршрута
        res = [end,parents.pop(end)]
        while parents:
            res.append(parents.pop(res[-1]))
        res.reverse()
        print(res)
    #бхаргава
        graph = dict(START={'A':6,'B':2},A={'END':1},B={'A':3,'END':5},END={})
        costs = dict(A=6, B=2, END=float('inf'))
        parents = dict(A='START',B='START',END=None)
        searched = []
        def find_lowest_cost_node(costs):
            lowest_cost = float('inf')
            lowest_cost_node = None
            for node in costs:
                cost = costs[node]
                if cost < lowest_cost and node not in searched:
                    lowest_cost = cost
                    lowest_cost_node = node
            return lowest_cost_node
        node = find_lowest_cost_node(costs) #среди необрботанных
        while node is not None: #пока есть необработанные #заменить на while node
            cost = costs[node]  #стоимость ноды
            neighbors = graph[node]       #удалить
            #соседи самой дешевой ноды
            for n in neighbors:
                new_cost = cost + neighbors[n]  #стоимость от старта + стоимость соседей
                if costs[n] > new_cost:
                    costs[n] = new_cost
                    parents[n] = node
            searched.append(node)
            node = find_lowest_cost_node(costs)
    #моя реализация на классах
        class Dijkstra:
            def find_lowest_cost_node(self, costs):
                costs = costs.copy()
                [costs.pop(node) for node in self.searched if node in self.searched]
                if costs:
                    return min(zip(costs.values(),costs.keys()))[1]
            def search(self,graph,start,end):
                costs = graph[start].copy()
                costs.update({end:float('inf')})
                parents = dict(zip(graph[start],[start]*len(graph[start])))
                parents.update({end:None})
                self.searched = []
                node = self.find_lowest_cost_node(costs)
                while node:
                    cost = costs[node]
                    neighbors = graph[node]
                    for neighbor in neighbors:
                        new_cost = cost + neighbors[neighbor]
                        if costs[neighbor] > new_cost:
                            costs[neighbor] = new_cost
                            parents[neighbor] = node
                    self.searched.append(node)
                    node = self.find_lowest_cost_node(costs)
                return parents
            def __init__(self):
                pass
            def __call__(self, graph, start, end):
                parents = self.search(graph, start, end)
                way = self.route(parents)
                return way
            def route(self,parents):
                #построение маршрута
                res = [end,parents.pop(end)]
                while parents:
                    res.append(parents.pop(res[-1]))
                res.reverse()
                return res
        find_way = Dijkstra()
        print(find_way(graph, start, end))
АЛГОРИТМЫ ПОИСКА КРАТЧАЙШЕГО ПУТИ
#применяются для:
 ии(напр игры в шашки) (кратчайший путь к победе)
 корректировки/изменения данных(за минимальное число изменений)(напр проверка правописания) (алгориФм-> алгориТм)
#в цикличных графах с отрицательными ребрами можно попасть в inf цикл бесконечно уменьшая стоимость
#помню был алгоритм удаляющий из графа самые тяжелые ребра, пока он не потеряет связность(ПРИМА?)
    КАК ПРОВЕРИТЬ СВЯЗНОСТЬ ГРАФА?
АЛГ. БЕЛЛМАНА-ФОРДА
#поиск кратчайшего пути в графе с ребрами с отрицательным весом
МЕТОДЫ РЕШЕНИЯ ЗАДАЧ
#вопросы при решении задач
  можно ли представить задачу в виде графа?
  можно ли воспользоваться хеш-табл
    РАЗДЕЛЯЙ И ВЛАСТВУЙ
    #разбивает задачи на базовый и рекурсивный случай
    #разделение задачи на уменьшающиеся фрагменты
        1. Определяем простейший случай как базовый
        2. задача бьется на рекурсивные случаи пока не будет сведена к базовому
        #при КАЖД рекурсивном вызове задача должна сокращаться
    #общая стратегия решения задач не решающихся ни одним из известных (мне) алг
    #рекурсивный метод решения задач
    #алгоритмы не слишком полезны if способны решать задачи лишь одного типа - разделяй и властвую помогает выработать новый подход к решению задач
    #основа рекурсивных алг
    ЖАДНЫЕ АЛГ?
    #получение приближенного ответа при отсутствии эффективного решения
        СОСТАВЛЕНИЕ РАСПИСАНИЯ?
        ЗАДАЧА О РЮКЗАКЕ?
        ЗАДАЧА О ПОКРЫТИИ МН-ВА?
            ПРИБЛИЖЕННЫЕ АЛГ?
        NP-ПОЛНЫЕ ЗАДАЧИ?
            ЗАДАЧА О КОММИВОЯЖЕРЕ?
            #сложность O(n!) (n-1)!/2; считается что решить ее быстро нельзя
            #не сущ относительно быстрых (?детерминированных) алг
            #Задача коммивояжёра (TSP(Travelling salesman problem))
            #сущ мн-во частных и обобщенных случае задачи
            #нужно объехать 5 городов с минимальным расстоянием(временем)
            {марин, беркли, сан-франциско, пало альто, фремонт}
                #варианты решения
                    #перебор всех вариантов - n!
            ОПРЕДЕЛЕНИЕ NP-ПОЛНОТЫ?
    ДИНАМИЧЕСКОЕ ПРОГРАММИРОВАНИЕ?
        ЗАДАЧА О РЮКЗАКЕ?
        АЛГ ИГРЫ В ШАШКИ
АЛГОРИТМ ЕВКЛИДА
#докво
    I. ПУСТЬ a = bq + r => НОД(a,b) = НОД(b,r) (вынос)
    II. НОД(r, 0) = r для ЛЮБОГО r!=0 (т.к. 0 делится на ЛЮБОЕ int)
#эффективный алгоритм нахождения нод/общей меры двух отрезков        
АЛГОРИТМ k БЛИЖАЙШИХ СОСЕДЕЙ?
#простой алг машинного обучения
#используется для прогнозирования:
  построения рекомендательных сис-м
  оптическое распознавание текста
    РЕГРЕССИЯ?
    ВЫБОР ПРИЗНАКОВ?
алгоритмы теории графов м.б. использованы для создания игрового AI
МАШИННОЕ ОБУЧЕНИЕ?
    OCR?
    ПОСТРОЕНИЕ SPAM-фильтра?
    ПРОГНОЗЫ НА БИРЖЕВЫХ ТОРГАХ?
ДЕРЕВЬЯ
#по идее ориентированный граф - дерево только if все связи однонаправленны от корня к ветвям(или наоборот)
    (дерево)     (дерево)  (не дерево)
     A←─┐      A──┐      A←─┐
     ↑  │     ↓  ↓      ↓  │
     B  C      B  C       B  C
#по идее обход b-tree можно делать рекурсивно передавая правую и левую часть себе же пока не наткнешся на искомое
ИНВЕРТИРОВАННЫЕ ИНДЕКСЫ?
ПРЕОБРАЗОВАНИЕ ФУРЬЕ?
ПАРАЛЛЕЛЬНЫЕ АЛГ?
MapReduce
    НАЗНАЧЕНИЕ РАСПРЕД АЛГ?
ФИЛЬТРЫ БЛУМА?
HyperLogLog?
АЛГОРИТМЫ SHA?
    СРАВНЕНИЕ ФАЙЛОВ?
    ПРОВЕРКА ПАРОЛЕЙ?
ЛОКАЛЬНО-ЧУВСТВИТЕЛЬНОЕ ХЕШИРОВАНИЕ?
ОБМЕН КЛЮЧАМИ ДИФФИ-ХЕЛЛМАНА?
ЛИНЕЙНОЕ ПРОГРАММИРОВАНИЕ?
параллелизм?
Стренг - автор классической книги по алг
CLRS - Кормен, Лейзерсон, Ривест, Штайн
отличие массива/связанного списка => метафора: поиск мест для компании в кинотеатре
примеры кода(кажется полностью дублируют книгу)
    www.manning.com/books/grokking-algorithms
    github.com/egonschiele/grokking-algorithms
код использует python 2.7
adit.io блог Адитьи Бхаргавы
gps использует алг из теории графов для нахождения кратчайшего пути
БИНАРНЫЕ ДЕРЕВЬЯ ПОИСКА?
#b-деревья;b-tree;...
крупные БД представляют делятся на несколько БД состоящих из хеш-таблиц/b-деревьев...
задача: найти несколько минимальных эл-тов в массиве
    def minimum_elt(seq):
        m,n = seq[0],seq[1]
        for i in seq[1:]:
            if i < m:
                m = i
            #не выйдет использовать elif
            if i < n and i!=m:
                n = i
        return m,n
задача: MAX ЭЛ-Т В МАССИВЕ РЕКУРСИВНО
    #v0 внутренняя fx
    def max(seq):
        def inner(a,b):
            return a if a > b else b
        if len(seq) == 1:
            return seq[0]
        else:
            return inner(seq[0], max(seq[1:])
    L = [2, 1, 4, 0, 9, 8, 2, 1, 0, 4, 9, 8]
    print(max(L) == 9)      >> True
    #v1
    def max(seq):
        def inner(a,b):
            if a>b:
                return a
            else:
                return b
        if len(seq) == 2:
            return inner(seq[0], seq[1])
        else:
            return inner(seq[0], max(seq[1:]))
    #v2
    def max(S):
        if len(S) == 1:
            return S[0]
        else:
            prev = max(S[:-1])
            curr = S[-1]
            if prev > curr:
                return prev
            else:
                return curr
    #bhargava
    def max(L):
        if len(L) == 2:
            return L[0] if L[0] > L[1] else L[1]
        sub_max = max(L[1:])
        return L[0] if L[0] > sub_max else sub_max
СОРТИРОВКА ПУЗЫРЬКОМ
#buble sort
#узкое место - крайние val для сортировки которых может потребовать пройти массив n раз - можно обойти, например:
  #скорее всего бред
  пройдя массив раз и вычислив среднее val
  разбив массив на два подмассива - меньше и больше среднего
    def bubble_sort(seq):
        j = 0
        while j < len(seq)-2: #j начинается с нуля(-1), и не считается первый элт(-1)
            elt = seq[0]
            #чтобы избавиться от остатка j на пред итерации т.к j может попасть на сформированный кусок в конце на пред итерации
            j = 0
            #if эл-ты равны - неважно куда их ставить
            for i in range(1, len(L)):#походу enumerate здесь не подойдет т.к. здесь есть все i кроме последнего, и в конце будет out of range
                '''здесь для массива можно было бы сохранять элт в другой var
                     удалять сначала правый элт, а затем вставлять по идее это должно быть быстрее
                     #да не, на мой взгляд не большая разница
                     [3, 7, 6, 5, 0, 8, 4]
                     v1
                        [3, (6), {7, 6, 5, 0, 8, 4}] #двигаем блок из 6 эл-тов
                        [3, 6, 7, (6), {5, 0, 8, 4}] #удаляем 6 и двигаем блок из 4 эл-тов
                     v2
                        [3, 7, (6), {5, 0, 8, 4}]     #переносим 6 в temp, двигаем 4 элта
                        [3, (6), {7, 5, 0, 8, 4}]     #вставляем 6, двигаем 5 элтов
                     вроде по цп хуже(на одну операцию больше), а по mem слегка лучше
                     '''
                if seq[i] <= elt:
                    #insert перед эл-том
                    seq.insert(i-1, seq[i])
                    seq.pop(i+1)
                    elt = seq[i]
                    j = 0
                else:
                    j += 1
                    elt = seq[i]
        return seq
    import random
    L = [*range(100)]
    random.shuffle(L)
    #L = [7, 3, 6, 5, 0, 8, 4]
    print(bubble_sort(L))
    #deque вместо list Работает в два раза МЕДЛЕННЕЕ(на малом наборе данных)
        s = '''
            from collections import deque
            import random
            def undef_sort(seq):
                seq = deque(seq)
                j = 0
                while j < len(seq)-2: #j начинается с нуля(-1), и не считается первый элт(-1)
                    elt = seq[0]
                    j = 0
                    for i in range(1, len(seq)):
                        if seq[i] <= elt:
                            seq.insert(i-1, seq[i])
                            del seq[i+1]
                            elt = seq[i]
                            j = 0
                        else:
                            j += 1
                            elt = seq[i]
                return seq
            D = deque(range(1000))
            random.shuffle(D)
            print(undef_sort(D))
            '''
        import timeit
        print(timeit.repeat(s,number=1))
СОРТИРОВКА РАСЧЕСКОЙ
#модификация пузырьковой
#?=ШЕЛЛА
СОРТИРОВКА ШЕЛЛА
#модификация пузырьковой
#=? расческой
РЕКУРСИЯ
#метод
#вроде при вызове fx в fx куда-то там передается управление
#inf рекурсия приводит к переполнению стека
ЗАДАЧА: рекурсивный обратный отсчет
    def countdown(i):
        if i < 0: return
        print(i)
        countdown(i-1)
    #вроде покрасивее, но возвращает i при передачи отрицательного val
    def countdown(i):
        print(i)
        if i <= 0:
            return
        else:
            countdown(i-1)
ЗАДАЧА: вычисление факториала рекурсией
#ps факториал для не целых положительных не имеет смысла
    def fact(n):
        if n > 1:
            return n*fact(n-1)
        else:
            return 1
РЕКУРСИЯ VS ЦИКЛЫ
    РЕКУРСИЯ
    #может ускорить работу разработчика stackoverflow.com/a/72694/139117
    #применяется только когда может увеличить читабельность
    ЦИКЛЫ
    #могут ускорить программу
ЗАДАЧА: ПРОСМОТР КОРОБОК
#(очередь?стек?куча?)
    сложить коробки в кучу
    пока (в куче коробки):
        взять коробку
        if key in коробка:
            break #куча.append(key)
        elif в коробке коробка:
            куча.append(коробка)
    #разумеется сработает только присохранении состояния
    def look_for_key(main_box):
        #pile = main_box.make_a_pile_to_look_through() # создаем кучу(pile) и складываем в нее коробки
        pile = [main_box]
        keys = []           #лучше использовать сохранение состояния
        while pile:
            box = pile.pop(0)
            for item in box:
                if isinstance(item,list):
                    pile.append(item)
                elif item == 'key':
                    keys.append(item)
        return keys
        L = [1,[2,[3,[4],['key']]]]
        print(look_for_key(L))
#по идее это стек т.к. lifo
        L = [1,[2,[3,[4],['key']]]]
        def find_key(seq):
            res = []
            keys = []
            seq = [seq]                                                   #ok
            while seq:
                #left теперь в любом случае вложенный
                left = seq.pop(0)
                for elt in left:
                    if isinstance(elt, list):
                        #можно использовать и append, но это уже будет называться не стек
                        seq.insert(0,elt)
                    elif elt == 'key':
                        keys.append(elt)
                    else:
                        res.append(elt)
            return res, keys
        print(find_key(L))
#это дек т.к. мы вытаскиваем элты в начале и добавляем их содержимое в конец
    L = [1,[2,[3,[4],['key']]]]
    def find_keys(seq):
        seq = seq.copy()
        keys = []
        res = []
        while seq:
            left = seq.pop()
            if isinstance(left, list):
                seq.extend(left)
            elif left == 'key':
                keys.append(left)
            else:
                res.insert(0, left)
        return res,keys
    print(find_keys(L))        
#рекурсия
    проверить коробку:
        if коробка:
            проверить коробку
        elif: break
    #
    def look_for_key(box):
        for item in box:
            if isinstance(item, list):
                look_for_key(item)
            elif item == 'key':
                print('found_the_key!')
                
    L = [1,[2,[3,[4],['key']]]]
    look_for_key(L)
    #сохранение состояния
        #атрибуты
            def find_key(seq):
                def inner(seq):
                    res = []
                    for i in seq:
                        if isinstance(i, list):
                            res.extend(inner(i))
                        elif i == 'key':
                            inner.keys.append(i)
                        else:
                            res.append(i)
                    return res
                inner.keys = []
                return inner(seq),inner.keys
            L = [1,[2,[3,'key',[4],['key']]]]
            print(find_key(L))
        #mutable
            def find_key(seq):
                keys = []
                def inner(seq):
                    res = []
                    for i in seq:
                        if isinstance(i, list):
                            res.extend(inner(i))
                        elif i == 'key':
                            keys.append(i)
                        else:
                            res.append(i)
                    return res
                return inner(seq),keys
            L = [1,[2,[3,'key',[4],['key']]]]
            print(find_key(L))
УПРАВЛЕНИЕ MEM
при выделении mem ос оперирует страницами(вроде 4кб) и возвращает указатель на страницу
МЕХАНИЗМ ПОДКАЧКИ СТРАНИЦ
malloc в linux запрашивает mem у менеджера памяти процесса в котором работает, оперирующего заранее выделенной mem и в случае необходимости запрашивающего довыделения памяти на этот процесс у системного менеджера(работающего со страничной адресацией)
Haskell
# не умеет в циклы? -> использует рекурсию
    СУММА ЭЛ-ТОВ МАССИВА
        sum [] = 0  #базовый случай #определение fx для пустого массива
        sum (x:xs) = x + (sum xs)   # рекурсивный случай (кажется это fx) определение fx для не пустого массива
        #эквивалент на if
            sum arr = if arr == []
                      then 0
                      else (head arr) + (sum (tail arr))


Heapsort != binary-tree sort
jsort?